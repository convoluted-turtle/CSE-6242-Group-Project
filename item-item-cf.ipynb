{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import difflib\n",
    "import string\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/justinvhuang/Desktop/CSE-6242-Group-Project/users-score-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_count = df.groupby('user_id')['anime_id'].count()\n",
    "\n",
    "user_ids_to_drop = anime_count[anime_count < 10].index\n",
    "\n",
    "filtered_df = df[~df['user_id'].isin(user_ids_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinvhuang/miniforge3/envs/spacy/lib/python3.8/site-packages/pandas/core/reshape/reshape.py:134: PerformanceWarning: The following operation may generate 3215923296 cells in the resulting pandas object.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix = filtered_df.pivot_table(index='user_id', columns='Anime Title', values='rating')\n",
    "\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "user_ratings_mean = user_item_matrix.mean(axis=1)\n",
    "user_item_matrix_centered = user_item_matrix.sub(user_ratings_mean, axis=0)\n",
    "\n",
    "item_similarity = cosine_similarity(user_item_matrix_centered.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(title1, title2):\n",
    "    title1_tokens = set(title1.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
    "    title2_tokens = set(title2.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
    "    intersection = len(title1_tokens.intersection(title2_tokens))\n",
    "    union = len(title1_tokens.union(title2_tokens))\n",
    "    return intersection / union if union else 0\n",
    "\n",
    "def item_collaborative_recommender(anime_title, user_item_matrix, item_similarity, top_n=10):\n",
    "    sim_scores = item_similarity[user_item_matrix.columns.get_loc(anime_title)]\n",
    "    \n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:2*top_n+1]  \n",
    "    \n",
    "    similar_titles = []\n",
    "    for idx in top_indices:\n",
    "        title = user_item_matrix.columns[idx]\n",
    "        if jaccard_similarity(anime_title, title) < 0.5:  \n",
    "            similar_titles.append(title)\n",
    "        if len(similar_titles) >= top_n:\n",
    "            break\n",
    "    \n",
    "    return similar_titles[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Death Note', 'Code Geass: Hangyaku no Lelouch', 'Fullmetal Alchemist', 'Elfen Lied: Tooriame nite Arui wa, Shoujo wa Ikani Shite Sono Shinjou ni Itatta ka? - Regenschauer', 'Code Geass: Hangyaku no Lelouch R2', 'Higurashi no Naku Koro ni', 'Claymore', 'Hellsing', 'Clannad', 'Highschool of the Dead']\n"
     ]
    }
   ],
   "source": [
    "recommendations = item_collaborative_recommender('Elfen Lied', user_item_matrix, item_similarity)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Anime Titles: 100%|██████████| 16608/16608 [00:20<00:00, 811.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store recommendations\n",
    "anime_recommendations_dict = {}\n",
    "\n",
    "# Group the DataFrame by 'Anime Title' to avoid repeated computations\n",
    "grouped_df = filtered_df.groupby('Anime Title')\n",
    "\n",
    "# Loop through unique anime titles with tqdm for a progress bar\n",
    "for anime_title, anime_group in tqdm(grouped_df, total=len(grouped_df), desc=\"Processing Anime Titles\"):\n",
    "    # Assuming you want to use the first anime_id for each anime_title (you may need to adjust this logic)\n",
    "    anime_id = anime_group['anime_id'].iloc[0]\n",
    "    \n",
    "    # Generate recommendations for the current anime title\n",
    "    recommendations = item_collaborative_recommender(anime_title, user_item_matrix, item_similarity)\n",
    "    \n",
    "    # Store the recommendations in the dictionary with anime_id as the key\n",
    "    anime_recommendations_dict[anime_id] = recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# File path to save the dictionary\n",
    "file_path = \"anime_recommendations.pkl\"\n",
    "\n",
    "# Save the dictionary using pickle\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(anime_recommendations_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
