{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.1+cu118\n",
      "Cornac version: 1.18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split as sk_split\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# set seed for reproducability\n",
    "SEED = 42\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 50\n",
    "ENCODER_DIMS = [100]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\jvhua\\OneDrive\\Desktop\\CSE-6242-Group-Project\\users-score-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_count = df.groupby('user_id')['anime_id'].count()\n",
    " \n",
    "user_ids_to_drop = anime_count[anime_count < 10].index\n",
    " \n",
    "filtered_df = df[~df['user_id'].isin(user_ids_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_df[['user_id', 'anime_id', 'rating']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split_ratio(ratio):\n",
    "    \"\"\"Generate split ratio lists.\n",
    "\n",
    "    Args:\n",
    "        ratio (float or list): a float number that indicates split ratio or a list of float\n",
    "        numbers that indicate split ratios (if it is a multi-split).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "        - bool: A boolean variable multi that indicates if the splitting is multi or single.\n",
    "        - list: A list of normalized split ratios.\n",
    "    \"\"\"\n",
    "    if isinstance(ratio, float):\n",
    "        if ratio <= 0 or ratio >= 1:\n",
    "            raise ValueError(\"Split ratio has to be between 0 and 1\")\n",
    "\n",
    "        multi = False\n",
    "    elif isinstance(ratio, list):\n",
    "        if any([x <= 0 for x in ratio]):\n",
    "            raise ValueError(\n",
    "                \"All split ratios in the ratio list should be larger than 0.\"\n",
    "            )\n",
    "\n",
    "        # normalize split ratios if they are not summed to 1\n",
    "        if math.fsum(ratio) != 1.0:\n",
    "            ratio = [x / math.fsum(ratio) for x in ratio]\n",
    "\n",
    "        multi = True\n",
    "    else:\n",
    "        raise TypeError(\"Split ratio should be either float or a list of floats.\")\n",
    "\n",
    "    return multi, ratio\n",
    "\n",
    "def split_pandas_data_with_ratios(data, ratios, seed=42, shuffle=False):\n",
    "    \"\"\"Helper function to split pandas DataFrame with given ratios\n",
    "\n",
    "    Note:\n",
    "        Implementation referenced from `this source <https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test>`_.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Pandas data frame to be split.\n",
    "        ratios (list of floats): list of ratios for split. The ratios have to sum to 1.\n",
    "        seed (int): random seed.\n",
    "        shuffle (bool): whether data will be shuffled when being split.\n",
    "\n",
    "    Returns:\n",
    "        list: List of pd.DataFrame split by the given specifications.\n",
    "    \"\"\"\n",
    "    if math.fsum(ratios) != 1.0:\n",
    "        raise ValueError(\"The ratios have to sum to 1\")\n",
    "\n",
    "    split_index = np.cumsum(ratios).tolist()[:-1]\n",
    "\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1, random_state=seed)\n",
    "\n",
    "    splits = np.split(data, [round(x * len(data)) for x in split_index])\n",
    "\n",
    "    # Add split index (this makes splitting by group more efficient).\n",
    "    for i in range(len(ratios)):\n",
    "        splits[i][\"split_index\"] = i\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "def python_random_split(data, ratio=0.75, seed=42):\n",
    "    \"\"\"Pandas random splitter.\n",
    "\n",
    "    The splitter randomly splits the input data.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Pandas DataFrame to be split.\n",
    "        ratio (float or list): Ratio for splitting data. If it is a single float number\n",
    "            it splits data into two halves and the ratio argument indicates the ratio\n",
    "            of training data set; if it is a list of float numbers, the splitter splits\n",
    "            data into several portions corresponding to the split ratios. If a list is\n",
    "            provided and the ratios are not summed to 1, they will be normalized.\n",
    "        seed (int): Seed.\n",
    "\n",
    "    Returns:\n",
    "        list: Splits of the input data as pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    multi_split, ratio = process_split_ratio(ratio)\n",
    "\n",
    "    if multi_split:\n",
    "        splits = split_pandas_data_with_ratios(data, ratio, shuffle=True, seed=seed)\n",
    "        splits_new = [x.drop(\"split_index\", axis=1) for x in splits]\n",
    "\n",
    "        return splits_new\n",
    "    else:\n",
    "        return sk_split(data, test_size=None, train_size=ratio, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 193637\n",
      "Number of items: 16057\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=SEED,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e980ff86754f0d81b23b6f4ca70933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4976.28 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bivae.fit(train_set)\n",
    "end_time = time.time()\n",
    "print(\"Took {:.2f} seconds for training.\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac_utils import predict_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# all_predictions = predict_ranking(bivae, train, usercol='userID', itemcol='itemID', remove_seen=True)\n",
    "# end_time = time.time()\n",
    "# print(\"Took {:.2f} seconds for prediction.\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metrics import map, ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_map = map(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "# eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
