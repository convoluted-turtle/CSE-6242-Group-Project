{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import difflib\n",
    "import string\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/justinvhuang/Desktop/CSE-6242-Group-Project/users-score-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the pickle file in binary read mode and load the pickled object\n",
    "with open(\"my_animelist.pkl\", 'rb') as f:\n",
    "    loaded_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11565"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['anime_id'].isin(loaded_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_count = df.groupby('user_id')['anime_id'].count()\n",
    "\n",
    "user_ids_to_drop = anime_count[anime_count < 10].index\n",
    "\n",
    "filtered_df = df[~df['user_id'].isin(user_ids_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = filtered_df.pivot_table(index='user_id', columns='Anime Title', values='rating')\n",
    "\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "user_ratings_mean = user_item_matrix.mean(axis=1)\n",
    "user_item_matrix_centered = user_item_matrix.sub(user_ratings_mean, axis=0)\n",
    "\n",
    "item_similarity = cosine_similarity(user_item_matrix_centered.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(title1, title2):\n",
    "    title1_tokens = set(title1.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
    "    title2_tokens = set(title2.lower().translate(str.maketrans('', '', string.punctuation)).split())\n",
    "    intersection = len(title1_tokens.intersection(title2_tokens))\n",
    "    union = len(title1_tokens.union(title2_tokens))\n",
    "    return intersection / union if union else 0\n",
    "\n",
    "def item_collaborative_recommender(anime_title, user_item_matrix, item_similarity, top_n=10):\n",
    "    sim_scores = item_similarity[user_item_matrix.columns.get_loc(anime_title)]\n",
    "    \n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:2*top_n+1]  \n",
    "    \n",
    "    similar_titles = []\n",
    "    for idx in top_indices:\n",
    "        title = user_item_matrix.columns[idx]\n",
    "        if jaccard_similarity(anime_title, title) < 0.5:  \n",
    "            similar_titles.append(title)\n",
    "        if len(similar_titles) >= top_n:\n",
    "            break\n",
    "    \n",
    "    return similar_titles[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great Teacher Onizuka', 'Hunter x Hunter', 'Shijou Saikyou no Deshi Kenichi', 'One Piece', 'Eyeshield 21', 'Kenpuu Denki Berserk', 'Hunter x Hunter (2011)', 'Major S1', 'Fullmetal Alchemist: Brotherhood', 'Code Geass: Hangyaku no Lelouch']\n"
     ]
    }
   ],
   "source": [
    "recommendations = item_collaborative_recommender('Hajime no Ippo', user_item_matrix, item_similarity)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Anime Titles: 100%|██████████| 9652/9652 [00:08<00:00, 1109.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store recommendations\n",
    "anime_recommendations_dict = {}\n",
    "\n",
    "# Group the DataFrame by 'Anime Title' to avoid repeated computations\n",
    "grouped_df = filtered_df.groupby('Anime Title')\n",
    "\n",
    "# Loop through unique anime titles with tqdm for a progress bar\n",
    "for anime_title, anime_group in tqdm(grouped_df, total=len(grouped_df), desc=\"Processing Anime Titles\"):\n",
    "    # Assuming you want to use the first anime_id for each anime_title (you may need to adjust this logic)\n",
    "    anime_id = anime_group['anime_id'].iloc[0]\n",
    "    \n",
    "    # Generate recommendations for the current anime title\n",
    "    recommendations = item_collaborative_recommender(anime_title, user_item_matrix, item_similarity)\n",
    "    \n",
    "    # Store the recommendations in the dictionary with anime_id as the key\n",
    "    anime_recommendations_dict[anime_id] = recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# File path to save the dictionary\n",
    "file_path = \"anime_recommendations_item_knn_CF_10k.pkl\"\n",
    "\n",
    "# Save the dictionary using pickle\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(anime_recommendations_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "title2id = {x:y for x,y in zip(df['Anime Title'], df['anime_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_anime_titles(user_dict, replacement_dict):\n",
    "    for user_id, anime_list in user_dict.items():\n",
    "        for i, anime_title in enumerate(anime_list):\n",
    "            if anime_title in replacement_dict:\n",
    "                user_dict[user_id][i] = replacement_dict[anime_title]\n",
    "    return user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dict_recs = replace_anime_titles(anime_recommendations_dict, title2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# File path to save the dictionary\n",
    "file_path = \"anime_recommendations_item_knn_CF_10k_num.pkl\"\n",
    "\n",
    "# Save the dictionary using pickle\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(cf_dict_recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
